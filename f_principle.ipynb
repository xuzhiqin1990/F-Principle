{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ml_collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"alpha\": 0,\n",
    "    \"x_start\": -5,\n",
    "    \"x_end\": 5,\n",
    "    \"train_size\": 101,\n",
    "    \"test_size\": 51,\n",
    "    \"layer_list\": [200, 200, 200, 100],\n",
    "    \"seed\": 0,\n",
    "    \"ActFun\": \"tanh\",\n",
    "    \"dims_input\": 1,\n",
    "    \"dims_output\": 1,\n",
    "    \"lossfunc\": \"MSE\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"epochs\": 300,\n",
    "    \"batch_size\": 50,\n",
    "    \"lr\": 2e-4,\n",
    "    \"lr_decayrate\": 0,\n",
    "    \"lr_decaystep\": 2000,\n",
    "    \"isFFT\": True,\n",
    "    \"result_dir\": 'results'\n",
    "}\n",
    "config = ml_collections.ConfigDict(config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Function\n",
    "Design a target function by discretizing a smooth function $f_{0}(x)$ by\n",
    "$$f(x) = \\alpha * Round(f_{0}(x)/\\alpha)$$\n",
    "In the case, we use $f_{0}(x) = \\sin(x) + 2\\sin(x) + 3\\sin(5x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func0(xx):\n",
    "    y_sin = np.sin(xx)+2*np.sin(3*xx)+3*np.sin(5*xx)\n",
    "    return y_sin\n",
    "\n",
    "\n",
    "def func_to_approx(xx, alpha):\n",
    "    y_sin = func0(xx)\n",
    "    if alpha == 0:\n",
    "        return y_sin\n",
    "    out_y = np.round(y_sin/alpha)\n",
    "    out_y2 = out_y * alpha\n",
    "    return out_y2\n",
    "\n",
    "\n",
    "def get_data(config):\n",
    "    train_input = np.reshape(np.linspace(config.x_start, config.x_end,\n",
    "                             num=config.train_size, endpoint=True), [config.train_size, 1]).astype(np.float32)\n",
    "\n",
    "    y_train = func_to_approx(train_input, config.alpha)\n",
    "\n",
    "    return (train_input, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.alpha = 0\n",
    "train_data, test_data = get_data(config)\n",
    "x, y = train_data\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fft(data, freq_len=40, x_input=np.zeros(10), kk=0, min_f=0, max_f=np.pi/3, isnorm=1):\n",
    "    second_diff_input = np.mean(np.diff(np.diff(np.squeeze(x_input))))\n",
    "    if abs(second_diff_input) < 1e-10:\n",
    "        datat = np.squeeze(data)\n",
    "        datat_fft = np.fft.fft(datat)\n",
    "        ind2 = range(freq_len)\n",
    "        fft_coe = datat_fft[ind2]\n",
    "        if isnorm == 1:\n",
    "            return_fft = np.absolute(fft_coe)\n",
    "        else:\n",
    "            return_fft = fft_coe\n",
    "    else:\n",
    "        return_fft = get_ft_multi(\n",
    "            x_input, data, kk=kk, freq_len=freq_len, min_f=min_f, max_f=max_f, isnorm=isnorm)\n",
    "    return return_fft\n",
    "\n",
    "\n",
    "def get_ft_multi(x_input, data, kk=0, freq_len=100, min_f=0, max_f=np.pi/3, isnorm=1):\n",
    "    n = x_input.shape[1]\n",
    "    if np.max(abs(kk)) == 0:\n",
    "        k = np.linspace(min_f, max_f, num=freq_len, endpoint=True)\n",
    "        kk = np.matmul(np.ones([n, 1]), np.reshape(k, [1, -1]))\n",
    "    tmp = np.matmul(np.transpose(data), np.exp(-1J * (np.matmul(x_input, kk))))\n",
    "    if isnorm == 1:\n",
    "        return_fft = np.absolute(tmp)\n",
    "    else:\n",
    "        return_fft = tmp\n",
    "    return np.squeeze(return_fft)\n",
    "\n",
    "\n",
    "def SelectPeakIndex(FFT_Data, endpoint=True):\n",
    "    D1 = FFT_Data[1:-1]-FFT_Data[0:-2]\n",
    "    D2 = FFT_Data[1:-1]-FFT_Data[2:]\n",
    "    D3 = np.logical_and(D1 > 0, D2 > 0)\n",
    "    tmp = np.where(D3 == True)\n",
    "    sel_ind = tmp[0]+1\n",
    "    if endpoint:\n",
    "        if FFT_Data[0]-FFT_Data[1] > 0:\n",
    "            sel_ind = np.concatenate([[0], sel_ind])\n",
    "        if FFT_Data[-1]-FFT_Data[-2] > 0:\n",
    "            Last_ind = len(FFT_Data)-1\n",
    "            sel_ind = np.concatenate([sel_ind, [Last_ind]])\n",
    "    return sel_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x, training=False)\n",
    "        # self.compiled_loss(y, y_pred)\n",
    "        # self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        return_metrics = {}\n",
    "        # for metric in self.metrics:\n",
    "        #     return_metrics[metric.name] = metric.result()\n",
    "        return_metrics['y_pred'] = y_pred\n",
    "\n",
    "        return return_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(config.dims_input, ))\n",
    "x = input\n",
    "for layer in config.layer_list:\n",
    "    x = tf.keras.layers.Dense(layer, activation=config.ActFun)(x)\n",
    "output = tf.keras.layers.Dense(config.dims_output)(x)\n",
    "\n",
    "model = CustomModel(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 3.0087 - val_loss: 2.8662 - val_y_pred: -0.0058\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8755 - val_loss: 2.9393 - val_y_pred: -0.0060\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9505 - val_loss: 2.8943 - val_y_pred: -0.0061\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9045 - val_loss: 2.8373 - val_y_pred: -0.0059\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8462 - val_loss: 2.8426 - val_y_pred: -0.0054\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8510 - val_loss: 2.8723 - val_y_pred: -0.0044\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8804 - val_loss: 2.8633 - val_y_pred: -0.0029\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8716 - val_loss: 2.8311 - val_y_pred: -0.0012\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8397 - val_loss: 2.8163 - val_y_pred: 6.7215e-04\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8256 - val_loss: 2.8267 - val_y_pred: 0.0027\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8370 - val_loss: 2.8365 - val_y_pred: 0.0046\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8480 - val_loss: 2.8278 - val_y_pred: 0.0064\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8401 - val_loss: 2.8088 - val_y_pred: 0.0083\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8221 - val_loss: 2.7990 - val_y_pred: 0.0097\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8131 - val_loss: 2.8041 - val_y_pred: 0.0111\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8186 - val_loss: 2.8113 - val_y_pred: 0.0122\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.8257 - val_loss: 2.8080 - val_y_pred: 0.0129\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8219 - val_loss: 2.7974 - val_y_pred: 0.0135\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8106 - val_loss: 2.7917 - val_y_pred: 0.0136\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8041 - val_loss: 2.7942 - val_y_pred: 0.0135\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8061 - val_loss: 2.7981 - val_y_pred: 0.0130\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8095 - val_loss: 2.7960 - val_y_pred: 0.0124\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8069 - val_loss: 2.7886 - val_y_pred: 0.0116\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7993 - val_loss: 2.7835 - val_y_pred: 0.0105\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7941 - val_loss: 2.7836 - val_y_pred: 0.0096\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7943 - val_loss: 2.7847 - val_y_pred: 0.0085\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7957 - val_loss: 2.7817 - val_y_pred: 0.0074\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7929 - val_loss: 2.7757 - val_y_pred: 0.0065\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7873 - val_loss: 2.7720 - val_y_pred: 0.0056\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.7839 - val_loss: 2.7717 - val_y_pred: 0.0046\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7838 - val_loss: 2.7712 - val_y_pred: 0.0039\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7836 - val_loss: 2.7680 - val_y_pred: 0.0033\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7806 - val_loss: 2.7637 - val_y_pred: 0.0026\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7765 - val_loss: 2.7611 - val_y_pred: 0.0022\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.7741 - val_loss: 2.7607 - val_y_pred: 0.0018\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7738 - val_loss: 2.7598 - val_y_pred: 0.0013\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7727 - val_loss: 2.7567 - val_y_pred: 0.0011\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7697 - val_loss: 2.7537 - val_y_pred: 7.1924e-04\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.7665 - val_loss: 2.7524 - val_y_pred: 3.3095e-04\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7650 - val_loss: 2.7516 - val_y_pred: -2.7745e-06\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7641 - val_loss: 2.7496 - val_y_pred: -3.0000e-04\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7621 - val_loss: 2.7467 - val_y_pred: -6.4718e-04\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7591 - val_loss: 2.7446 - val_y_pred: -9.4871e-04\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7569 - val_loss: 2.7435 - val_y_pred: -0.0012\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7556 - val_loss: 2.7416 - val_y_pred: -0.0014\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7539 - val_loss: 2.7393 - val_y_pred: -0.0016\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7514 - val_loss: 2.7367 - val_y_pred: -0.0016\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7489 - val_loss: 2.7350 - val_y_pred: -0.0016\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7473 - val_loss: 2.7332 - val_y_pred: -0.0015\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7457 - val_loss: 2.7309 - val_y_pred: -0.0013\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7435 - val_loss: 2.7285 - val_y_pred: -0.0011\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7412 - val_loss: 2.7265 - val_y_pred: -8.7388e-04\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7393 - val_loss: 2.7246 - val_y_pred: -5.2829e-04\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7376 - val_loss: 2.7226 - val_y_pred: -2.1975e-04\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7356 - val_loss: 2.7203 - val_y_pred: 9.1527e-05\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7333 - val_loss: 2.7183 - val_y_pred: 3.5561e-04\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7313 - val_loss: 2.7166 - val_y_pred: 4.9078e-04\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7295 - val_loss: 2.7146 - val_y_pred: 5.8777e-04\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7274 - val_loss: 2.7124 - val_y_pred: 6.5425e-04\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7254 - val_loss: 2.7102 - val_y_pred: 6.9946e-04\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7233 - val_loss: 2.7083 - val_y_pred: 6.5230e-04\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7214 - val_loss: 2.7061 - val_y_pred: 6.4937e-04\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7193 - val_loss: 2.7039 - val_y_pred: 5.4628e-04\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7171 - val_loss: 2.7019 - val_y_pred: 4.8159e-04\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7152 - val_loss: 2.7000 - val_y_pred: 3.2132e-04\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7131 - val_loss: 2.6980 - val_y_pred: 2.0744e-04\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7111 - val_loss: 2.6959 - val_y_pred: 1.0903e-04\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7090 - val_loss: 2.6938 - val_y_pred: 1.3362e-04\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7070 - val_loss: 2.6918 - val_y_pred: 1.2585e-04\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7050 - val_loss: 2.6897 - val_y_pred: 7.3913e-05\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7030 - val_loss: 2.6876 - val_y_pred: 1.8098e-04\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7009 - val_loss: 2.6856 - val_y_pred: 7.5874e-05\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6988 - val_loss: 2.6833 - val_y_pred: 6.7472e-05\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6968 - val_loss: 2.6812 - val_y_pred: 9.8570e-06\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6947 - val_loss: 2.6790 - val_y_pred: 1.4616e-04\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6925 - val_loss: 2.6767 - val_y_pred: 4.0835e-06\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6904 - val_loss: 2.6747 - val_y_pred: -6.7832e-06\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6884 - val_loss: 2.6724 - val_y_pred: -1.5855e-05\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6861 - val_loss: 2.6703 - val_y_pred: 9.4223e-05\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6840 - val_loss: 2.6682 - val_y_pred: 2.8261e-05\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6820 - val_loss: 2.6660 - val_y_pred: 2.6007e-05\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6798 - val_loss: 2.6637 - val_y_pred: 9.7455e-05\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6775 - val_loss: 2.6615 - val_y_pred: 8.3119e-05\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6754 - val_loss: 2.6594 - val_y_pred: 1.2118e-04\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6733 - val_loss: 2.6572 - val_y_pred: 2.1726e-04\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6712 - val_loss: 2.6548 - val_y_pred: 2.4862e-04\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6689 - val_loss: 2.6526 - val_y_pred: 3.9158e-04\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6667 - val_loss: 2.6504 - val_y_pred: 4.8022e-04\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6646 - val_loss: 2.6481 - val_y_pred: 5.0494e-04\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6623 - val_loss: 2.6460 - val_y_pred: 4.7843e-04\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6602 - val_loss: 2.6436 - val_y_pred: 4.7698e-04\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6579 - val_loss: 2.6413 - val_y_pred: 5.0587e-04\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6557 - val_loss: 2.6390 - val_y_pred: 4.8300e-04\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6534 - val_loss: 2.6366 - val_y_pred: 4.2779e-04\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6511 - val_loss: 2.6343 - val_y_pred: 4.8100e-04\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6489 - val_loss: 2.6320 - val_y_pred: 3.6687e-04\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6467 - val_loss: 2.6297 - val_y_pred: 2.9782e-04\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6444 - val_loss: 2.6272 - val_y_pred: 2.0034e-04\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6421 - val_loss: 2.6250 - val_y_pred: 1.5737e-04\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6398 - val_loss: 2.6227 - val_y_pred: 1.9856e-04\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6375 - val_loss: 2.6202 - val_y_pred: 6.2824e-05\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6352 - val_loss: 2.6178 - val_y_pred: 6.1208e-05\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6328 - val_loss: 2.6155 - val_y_pred: 9.6313e-05\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6305 - val_loss: 2.6132 - val_y_pred: 6.2145e-05\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6282 - val_loss: 2.6107 - val_y_pred: -1.1736e-05\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6260 - val_loss: 2.6084 - val_y_pred: 8.6847e-06\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6236 - val_loss: 2.6060 - val_y_pred: -2.9652e-05\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6213 - val_loss: 2.6034 - val_y_pred: -1.3589e-04\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.6188 - val_loss: 2.6009 - val_y_pred: -1.6348e-04\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6164 - val_loss: 2.5986 - val_y_pred: -1.5840e-04\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6140 - val_loss: 2.5961 - val_y_pred: -1.4118e-04\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6116 - val_loss: 2.5936 - val_y_pred: -1.3569e-04\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6092 - val_loss: 2.5910 - val_y_pred: -7.9014e-05\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6067 - val_loss: 2.5885 - val_y_pred: -1.4184e-04\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6042 - val_loss: 2.5861 - val_y_pred: -2.9737e-05\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6019 - val_loss: 2.5835 - val_y_pred: -4.3757e-05\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5993 - val_loss: 2.5810 - val_y_pred: -6.3923e-05\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5968 - val_loss: 2.5785 - val_y_pred: 8.2528e-05\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5944 - val_loss: 2.5758 - val_y_pred: -7.0545e-05\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5919 - val_loss: 2.5732 - val_y_pred: 2.6587e-05\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5893 - val_loss: 2.5706 - val_y_pred: 1.6011e-07\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5867 - val_loss: 2.5681 - val_y_pred: -3.2825e-05\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5843 - val_loss: 2.5655 - val_y_pred: 7.9707e-06\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5818 - val_loss: 2.5628 - val_y_pred: 1.4006e-05\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5791 - val_loss: 2.5602 - val_y_pred: -1.9857e-06\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5766 - val_loss: 2.5576 - val_y_pred: -3.6265e-05\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5739 - val_loss: 2.5549 - val_y_pred: -1.0702e-05\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5714 - val_loss: 2.5523 - val_y_pred: -1.7015e-05\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5689 - val_loss: 2.5495 - val_y_pred: -1.7788e-06\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5661 - val_loss: 2.5468 - val_y_pred: 2.4294e-05\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5635 - val_loss: 2.5442 - val_y_pred: 4.6468e-05\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5608 - val_loss: 2.5414 - val_y_pred: -4.3123e-05\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5581 - val_loss: 2.5387 - val_y_pred: -3.4754e-05\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5555 - val_loss: 2.5360 - val_y_pred: -6.2190e-05\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5527 - val_loss: 2.5332 - val_y_pred: -1.6355e-05\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5501 - val_loss: 2.5304 - val_y_pred: -2.1518e-05\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5473 - val_loss: 2.5276 - val_y_pred: 7.2148e-05\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5446 - val_loss: 2.5249 - val_y_pred: 8.1395e-05\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5419 - val_loss: 2.5218 - val_y_pred: 6.6100e-05\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5390 - val_loss: 2.5190 - val_y_pred: -2.4514e-05\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5362 - val_loss: 2.5162 - val_y_pred: 3.4342e-05\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5333 - val_loss: 2.5134 - val_y_pred: -2.9206e-05\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5306 - val_loss: 2.5104 - val_y_pred: -7.5710e-06\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5277 - val_loss: 2.5076 - val_y_pred: -3.4255e-05\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5248 - val_loss: 2.5047 - val_y_pred: -2.7103e-06\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.5220 - val_loss: 2.5016 - val_y_pred: 4.6889e-06\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5190 - val_loss: 2.4988 - val_y_pred: -5.7039e-05\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5161 - val_loss: 2.4957 - val_y_pred: -1.4286e-05\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5132 - val_loss: 2.4927 - val_y_pred: -2.1434e-05\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5103 - val_loss: 2.4897 - val_y_pred: -8.1257e-05\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5073 - val_loss: 2.4867 - val_y_pred: -9.7357e-05\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5042 - val_loss: 2.4838 - val_y_pred: -4.6040e-05\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5013 - val_loss: 2.4808 - val_y_pred: -7.8531e-05\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4984 - val_loss: 2.4778 - val_y_pred: -6.3585e-05\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4954 - val_loss: 2.4745 - val_y_pred: -1.0107e-04\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4922 - val_loss: 2.4714 - val_y_pred: -6.5659e-05\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.4891 - val_loss: 2.4683 - val_y_pred: -2.5961e-05\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4861 - val_loss: 2.4653 - val_y_pred: -8.5433e-06\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4829 - val_loss: 2.4620 - val_y_pred: -4.0531e-05\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4798 - val_loss: 2.4590 - val_y_pred: -3.8396e-05\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4768 - val_loss: 2.4558 - val_y_pred: -1.5286e-04\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4736 - val_loss: 2.4526 - val_y_pred: -1.6546e-04\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4704 - val_loss: 2.4493 - val_y_pred: -1.0451e-04\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4672 - val_loss: 2.4460 - val_y_pred: -1.1981e-04\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4639 - val_loss: 2.4427 - val_y_pred: -1.1911e-04\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4606 - val_loss: 2.4395 - val_y_pred: -1.1308e-04\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4574 - val_loss: 2.4362 - val_y_pred: -1.2644e-04\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4541 - val_loss: 2.4329 - val_y_pred: -1.4129e-04\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.4508 - val_loss: 2.4295 - val_y_pred: -1.0072e-04\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4473 - val_loss: 2.4261 - val_y_pred: -9.7012e-05\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4440 - val_loss: 2.4228 - val_y_pred: -7.1024e-05\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4407 - val_loss: 2.4193 - val_y_pred: -7.6392e-05\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4373 - val_loss: 2.4158 - val_y_pred: -1.3872e-04\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.4338 - val_loss: 2.4123 - val_y_pred: -4.7040e-05\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4303 - val_loss: 2.4088 - val_y_pred: -1.2520e-04\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4268 - val_loss: 2.4053 - val_y_pred: -1.2682e-04\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4234 - val_loss: 2.4017 - val_y_pred: -1.3760e-04\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4198 - val_loss: 2.3983 - val_y_pred: -9.6283e-05\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4163 - val_loss: 2.3947 - val_y_pred: -1.1976e-04\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.4127 - val_loss: 2.3910 - val_y_pred: -1.8393e-04\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4090 - val_loss: 2.3873 - val_y_pred: -9.9480e-05\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4054 - val_loss: 2.3837 - val_y_pred: -1.2426e-04\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4017 - val_loss: 2.3801 - val_y_pred: -2.0642e-04\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3981 - val_loss: 2.3764 - val_y_pred: -2.2771e-04\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3943 - val_loss: 2.3726 - val_y_pred: -1.8905e-04\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3905 - val_loss: 2.3690 - val_y_pred: -1.9553e-04\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3868 - val_loss: 2.3653 - val_y_pred: -1.7954e-04\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3831 - val_loss: 2.3612 - val_y_pred: -1.2745e-04\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3792 - val_loss: 2.3574 - val_y_pred: -1.8247e-04\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3754 - val_loss: 2.3537 - val_y_pred: -1.7056e-04\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3716 - val_loss: 2.3499 - val_y_pred: -5.1881e-05\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3676 - val_loss: 2.3460 - val_y_pred: -1.2618e-04\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3639 - val_loss: 2.3420 - val_y_pred: -1.0337e-04\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.3598 - val_loss: 2.3382 - val_y_pred: -1.3703e-04\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3559 - val_loss: 2.3342 - val_y_pred: -1.2884e-04\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3520 - val_loss: 2.3301 - val_y_pred: -1.9247e-04\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3478 - val_loss: 2.3260 - val_y_pred: -2.0807e-04\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.3438 - val_loss: 2.3220 - val_y_pred: -2.0943e-04\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3398 - val_loss: 2.3179 - val_y_pred: -2.0259e-04\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3356 - val_loss: 2.3138 - val_y_pred: -1.8188e-04\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3315 - val_loss: 2.3098 - val_y_pred: -2.3015e-04\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3274 - val_loss: 2.3058 - val_y_pred: -2.0109e-04\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3233 - val_loss: 2.3015 - val_y_pred: -2.1706e-04\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3191 - val_loss: 2.2973 - val_y_pred: -2.6071e-04\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3148 - val_loss: 2.2930 - val_y_pred: -2.0911e-04\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3105 - val_loss: 2.2888 - val_y_pred: -2.1015e-04\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.3063 - val_loss: 2.2846 - val_y_pred: -1.8003e-04\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3020 - val_loss: 2.2805 - val_y_pred: -1.3131e-04\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2977 - val_loss: 2.2763 - val_y_pred: -1.5567e-04\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2934 - val_loss: 2.2717 - val_y_pred: -2.8706e-04\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2890 - val_loss: 2.2674 - val_y_pred: -2.0253e-04\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2846 - val_loss: 2.2631 - val_y_pred: -1.9654e-04\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2802 - val_loss: 2.2587 - val_y_pred: -1.8334e-04\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2758 - val_loss: 2.2544 - val_y_pred: -2.1792e-04\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2714 - val_loss: 2.2500 - val_y_pred: -2.8282e-04\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2669 - val_loss: 2.2456 - val_y_pred: -2.3087e-04\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2624 - val_loss: 2.2411 - val_y_pred: -2.5161e-04\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2579 - val_loss: 2.2366 - val_y_pred: -2.1647e-04\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2533 - val_loss: 2.2320 - val_y_pred: -3.5423e-04\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2487 - val_loss: 2.2276 - val_y_pred: -3.4764e-04\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2442 - val_loss: 2.2230 - val_y_pred: -3.1696e-04\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2395 - val_loss: 2.2185 - val_y_pred: -3.4819e-04\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2349 - val_loss: 2.2139 - val_y_pred: -2.9219e-04\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2303 - val_loss: 2.2092 - val_y_pred: -1.9801e-04\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2256 - val_loss: 2.2046 - val_y_pred: -1.7784e-04\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2208 - val_loss: 2.1998 - val_y_pred: -2.2327e-04\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2161 - val_loss: 2.1952 - val_y_pred: -2.1370e-04\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2113 - val_loss: 2.1906 - val_y_pred: -1.9440e-04\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2066 - val_loss: 2.1858 - val_y_pred: -1.8321e-04\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2017 - val_loss: 2.1810 - val_y_pred: -2.0323e-04\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1969 - val_loss: 2.1760 - val_y_pred: -1.9384e-04\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1919 - val_loss: 2.1713 - val_y_pred: -3.0681e-04\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1869 - val_loss: 2.1666 - val_y_pred: -1.8533e-04\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1821 - val_loss: 2.1616 - val_y_pred: -2.2222e-04\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1770 - val_loss: 2.1566 - val_y_pred: -2.0634e-04\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1719 - val_loss: 2.1516 - val_y_pred: -3.1518e-04\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1668 - val_loss: 2.1466 - val_y_pred: -2.8404e-04\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1617 - val_loss: 2.1416 - val_y_pred: -2.1492e-04\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1566 - val_loss: 2.1367 - val_y_pred: -2.6566e-04\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1515 - val_loss: 2.1315 - val_y_pred: -1.9650e-04\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.1462 - val_loss: 2.1263 - val_y_pred: -2.4288e-04\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.1409 - val_loss: 2.1211 - val_y_pred: -2.0549e-04\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1357 - val_loss: 2.1158 - val_y_pred: -1.4746e-04\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1303 - val_loss: 2.1103 - val_y_pred: -1.8776e-04\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1249 - val_loss: 2.1049 - val_y_pred: -3.3391e-04\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.1195 - val_loss: 2.0995 - val_y_pred: -3.3215e-04\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1140 - val_loss: 2.0939 - val_y_pred: -2.4361e-04\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1085 - val_loss: 2.0885 - val_y_pred: -2.3051e-04\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.1030 - val_loss: 2.0827 - val_y_pred: -3.1577e-04\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0974 - val_loss: 2.0772 - val_y_pred: -3.0280e-04\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0918 - val_loss: 2.0716 - val_y_pred: -3.5060e-04\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0862 - val_loss: 2.0660 - val_y_pred: -3.2661e-04\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0807 - val_loss: 2.0604 - val_y_pred: -4.7187e-04\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0749 - val_loss: 2.0546 - val_y_pred: -3.8932e-04\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0691 - val_loss: 2.0488 - val_y_pred: -3.7108e-04\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0633 - val_loss: 2.0430 - val_y_pred: -4.4661e-04\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0574 - val_loss: 2.0372 - val_y_pred: -3.5135e-04\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0515 - val_loss: 2.0311 - val_y_pred: -3.5746e-04\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0454 - val_loss: 2.0253 - val_y_pred: -3.6670e-04\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0394 - val_loss: 2.0191 - val_y_pred: -3.8423e-04\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0331 - val_loss: 2.0129 - val_y_pred: -4.0667e-04\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0269 - val_loss: 2.0067 - val_y_pred: -3.9770e-04\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0206 - val_loss: 2.0004 - val_y_pred: -4.0746e-04\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0144 - val_loss: 1.9942 - val_y_pred: -4.0295e-04\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0081 - val_loss: 1.9877 - val_y_pred: -4.4287e-04\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0017 - val_loss: 1.9812 - val_y_pred: -3.9373e-04\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9953 - val_loss: 1.9747 - val_y_pred: -4.1496e-04\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9888 - val_loss: 1.9679 - val_y_pred: -4.2937e-04\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9822 - val_loss: 1.9613 - val_y_pred: -3.5733e-04\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9755 - val_loss: 1.9550 - val_y_pred: -5.4530e-04\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9691 - val_loss: 1.9483 - val_y_pred: -4.9424e-04\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9626 - val_loss: 1.9416 - val_y_pred: -5.8317e-04\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9557 - val_loss: 1.9346 - val_y_pred: -4.6017e-04\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9488 - val_loss: 1.9279 - val_y_pred: -5.1730e-04\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9421 - val_loss: 1.9210 - val_y_pred: -6.0203e-04\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9352 - val_loss: 1.9139 - val_y_pred: -5.3222e-04\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9281 - val_loss: 1.9072 - val_y_pred: -4.4682e-04\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9212 - val_loss: 1.9002 - val_y_pred: -4.2589e-04\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9143 - val_loss: 1.8933 - val_y_pred: -5.5733e-04\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9071 - val_loss: 1.8863 - val_y_pred: -4.4812e-04\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9001 - val_loss: 1.8790 - val_y_pred: -4.3377e-04\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8927 - val_loss: 1.8719 - val_y_pred: -3.1991e-04\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8854 - val_loss: 1.8647 - val_y_pred: -4.1604e-04\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8782 - val_loss: 1.8573 - val_y_pred: -4.5722e-04\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8706 - val_loss: 1.8500 - val_y_pred: -3.1401e-04\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8632 - val_loss: 1.8425 - val_y_pred: -3.3764e-04\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8554 - val_loss: 1.8349 - val_y_pred: -3.0453e-04\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8477 - val_loss: 1.8273 - val_y_pred: -3.8111e-04\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8399 - val_loss: 1.8197 - val_y_pred: -1.0962e-04\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8320 - val_loss: 1.8118 - val_y_pred: -1.4638e-04\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8238 - val_loss: 1.8042 - val_y_pred: 3.6354e-05\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8160 - val_loss: 1.7965 - val_y_pred: -9.3507e-05\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8079 - val_loss: 1.7887 - val_y_pred: -1.1279e-04\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8000 - val_loss: 1.7808 - val_y_pred: -5.4989e-05\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7918 - val_loss: 1.7728 - val_y_pred: -1.1932e-04\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7839 - val_loss: 1.7648 - val_y_pred: -3.1701e-06\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7758 - val_loss: 1.7566 - val_y_pred: -1.2724e-04\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7676 - val_loss: 1.7482 - val_y_pred: -6.4672e-05\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7594 - val_loss: 1.7402 - val_y_pred: 3.5819e-05\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7512 - val_loss: 1.7320 - val_y_pred: -1.5447e-04\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_data(config)\n",
    "x, y = train_data\n",
    "opt = tf.keras.optimizers.__dict__[config.optimizer](lr=config.lr)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "history = model.fit(x, y, batch_size=101,epochs=config.epochs, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = history.history['loss']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fff3a2c054a5d83053cb95d2ca3b099f5b8f713534c8bf128490ee39121907f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
